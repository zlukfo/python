{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Поиск фактов о персонах\n",
    "## Как работает\n",
    "1. На вход подаются массив неразмеченных текстов новостей. Как формирует массив читать ___\n",
    "2. При помощи библиотеки **natasha** массив последовательно предобрабатывается. В результате получаем последовательность рахмеченных документов\n",
    "3. Каждый документ разбивается на предложения, поиск фактов выполняется по каждому предложению\n",
    "## Правила поиска фактов  \n",
    "Для сущности персона описано несколько правил, определяющих различные типы фактов на основании синтаксического разбора предложения \n",
    "- **nsubj** - дествие (глагол) которое совешила персона \"Ширак *РОДИЛСЯ* в Париже\" (кто, что сделал, где)\n",
    "- **appos** - характеристика, кем является данная персона \"при *ПРЕЗЕДЕНТЕ* России Ельцине\" (кто, кем является, подробнее)\n",
    "- **obj** - действие, которое совершено над персоной \"суд *ПРИЗНАЛ* Навального виновным\" (кто, что с ним сделали, подробнее)\n",
    "- **iobj** - дествие (причастие) которое совешила персона \"Порошенко *ПРОИГРАВ* выборы\" (кто, что им сделано, подробнее)\n",
    "- **conj** - вторая персона \"Навальный *и Офицеров* (кто и кто)\"\n",
    "- **nmod** - что-то относится к персоне \"*ФОТОГРАФИЯ* Дональда Трампа\" (кто, что относится к нему)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разбор (разметка) корпуса текстов через natasha\n",
    "# на входе - корпус исходных текстов (калатог в котором 1 файл - 1 статья источника-сайта)\n",
    "# на выходе - ______________\n",
    "from pathlib import Path\n",
    "from ipymarkup import show_box_markup\n",
    "#from anytree import Node, RenderTree, resolver, walker\n",
    "#import networkx\n",
    "#import matplotlib.pyplot as plt\n",
    "from treelib import Node, Tree, exceptions\n",
    "\n",
    "from natasha import (\n",
    "    Segmenter,\n",
    "    MorphVocab,\n",
    "    \n",
    "    NewsEmbedding,\n",
    "    NewsMorphTagger,\n",
    "    NewsSyntaxParser,\n",
    "    NewsNERTagger,\n",
    "    \n",
    "    #PER,\n",
    "    NamesExtractor,\n",
    "    #AddrExtractor,\n",
    "    #DatesExtractor,\n",
    "    #MoneyExtractor,\n",
    "\n",
    "    Doc\n",
    ")\n",
    "\n",
    "def main (corpus_path: str):\n",
    "    # !!! внимание. исходные файлы должны быть сохранение в определенном формате\n",
    "    paths = Path(corpus_path).glob('*.txt')\n",
    "    COUNTER = 30\n",
    "    for filename in paths:\n",
    "        if not COUNTER:\n",
    "            break\n",
    "        with open(filename, encoding='utf-8') as fdr:\n",
    "            create_date, href, title, text = [line.strip('\\n') for line in fdr][:4]\n",
    "\n",
    "            segmenter = Segmenter()\n",
    "            morph_vocab = MorphVocab()\n",
    "\n",
    "            emb = NewsEmbedding()\n",
    "            morph_tagger = NewsMorphTagger(emb)\n",
    "            syntax_parser = NewsSyntaxParser(emb)\n",
    "            ner_tagger = NewsNERTagger(emb)\n",
    "            \n",
    "            doc = Doc(text)\n",
    "            doc.segment(segmenter)\n",
    "            doc.tag_morph(morph_tagger)\n",
    "            doc.parse_syntax(syntax_parser)\n",
    "            doc.tag_ner(ner_tagger)\n",
    "            \n",
    "\n",
    "            for token in doc.tokens:\n",
    "                token.lemmatize(morph_vocab)\n",
    "\n",
    "            for span in doc.spans:\n",
    "                span.normalize(morph_vocab)\n",
    "\n",
    "            for sent in doc.sents[:1]:\n",
    "                for span in sent.spans:\n",
    "                    for _ in sent.tokens:\n",
    "                        if span.tokens[0].id == _.id:\n",
    "                            s= {'type': span.type, 'text':_.text, 'rel':_.rel, 'head':_.head_id }  \n",
    "                    for _ in sent.tokens:\n",
    "                        if _.id == s['head']:\n",
    "                            s['head'] = _.text\n",
    "                    if s['type'] == 'PER':      \n",
    "                        print (sent.text)\n",
    "                        print(s)\n",
    "                        print('------------------')\n",
    "            \n",
    "            '''\n",
    "            for sent in doc.sents:\n",
    "                # по результату синтаксического разбора создаем дерево\n",
    "                tree = Tree()\n",
    "                tree.create_node('root', 'root')\n",
    "                \n",
    "                nodes = [tree.create_node(_.text, _.id, parent='root', \n",
    "                        data={'head_id':_.head_id, 'start':_.start, 'rel':_.rel, 'pos':_.pos}) \n",
    "                        for _ in sent.tokens]\n",
    "\n",
    "                for node in nodes:\n",
    "                    if node.identifier == node.data['head_id'] or not tree.get_node(node.data['head_id']):\n",
    "                        continue\n",
    "                    if node.data['rel'] == 'root':\n",
    "                        node.root = True\n",
    "                    try:\n",
    "                        tree.move_node(node.identifier, node.data['head_id'])\n",
    "                    except exceptions.LoopError:\n",
    "                        print ('loop')\n",
    "\n",
    "                print('-------------------')\n",
    "                print (sent.text)\n",
    "            '''\n",
    "            '''\n",
    "                https://universaldependencies.org/u/dep/index.html\n",
    "                источник -отношение-> цель\n",
    "                отнонение указывается в источнике но относится к цели\n",
    "                \n",
    "                obj - цель = объект, на который воздействует источник \n",
    "                nsubj - цель = источник относится ко мне\n",
    "                obl - цель = когда\n",
    "                nmod - цель = я принадлежу источнику\n",
    "                appos - цель = что из себя представляет источник\n",
    "\n",
    "                правила \n",
    "                PER\n",
    "                - nsubj - дествие (глагол) которое совешила персона \"Ширак РОДИЛСЯ в Париже\" (кто, что сделал, где)\n",
    "                - appos - характеристика, кем является данная персона \"при ПРЕЗЕДЕНТЕ России Ельцине\" (кто, кем является, подробнее)\n",
    "                - obj - действие, которое совершено над персоной \"суд ПРИЗНАЛ Навального виновным\" (кто, что с ним сделали, подробнее)\n",
    "                - iobj - дествие (причастие) которое совешила персона \"Порошенко ПРОИГРАВ выборы\" (кто, что им сделано, подробнее)\n",
    "                - conj - вторая персона \"Навальный и Офицеров (кто и кто)\"\n",
    "                - nmod - что-то относится к персоне \"ФОТОГРАФИЯ Дональда Трампа\" (кто, что относится к нему)\n",
    "\n",
    "            '''\n",
    "            '''\n",
    "\n",
    "                spans_id = {_.tokens[0].id: {'type':_.type, 'text':_.text, 'type':_.type} for _ in sent.spans}\n",
    "                for path in tree.paths_to_leaves():\n",
    "                    if set(path) & set(spans_id.keys()):\n",
    "                        result = [[tree[_].tag, tree[_].data[\"pos\"], tree[_].data[\"rel\"]]  for _ in path[1:]]\n",
    "                        for span_key, span_data in spans_id.items():\n",
    "                            if span_key in path:\n",
    "                                result = [span_data['text'], span_data['type']] + result\n",
    "                        print (result)\n",
    "\n",
    "\n",
    "                        #s = ' '.join([f'{tree[_].tag}/({tree[_].data[\"pos\"]})/{tree[_].data[\"rel\"]} ' for _ in path[1:]])\n",
    "                        #print (s)\n",
    "            '''         \n",
    "            '''\n",
    "            # !!! дерево построит нельзя потому что синтаксическое предложение в общем случае имеет циклы - это граф\n",
    "            finder = resolver.Resolver('name')\n",
    "            finder_start = resolver.Resolver('start')\n",
    "\n",
    "            for sent in doc.sents[:1]:\n",
    "              root = Node('#')\n",
    "              nodes = [Node(_.id, parent = root, parent_id=_.head_id, text=_.text, rel=_.rel, start=str(_.start)) for _ in sent.tokens]\n",
    "              for node in nodes:\n",
    "                try:\n",
    "                    node.parent = finder.get(root, node.parent_id)\n",
    "                except:\n",
    "                    pass\n",
    "              print ('---------------------')\n",
    "              print (RenderTree(root))\n",
    "              for span in [_.start for _ in sent.spans]:\n",
    "                print (finder_start.get(root, f'{span}'))\n",
    "              root = None\n",
    "            '''\n",
    "            '''\n",
    "            # объект - описание - дополнение\n",
    "            # Сергей Пугачев Бенефициар Межпромбанка \n",
    "            for sent in doc.sents[:1]:\n",
    "                words = [_.text for _ in sent.tokens]\n",
    "                spans = [(_.start, _.stop, _.type) for _ in sent.spans]\n",
    "                deps = [(int(_.head_id.split('_')[-1])-1, int(_.id.split('_')[-1])-1, _.rel) for _ in sent.tokens]\n",
    "                \n",
    "                spans2 = {f'{_.start}': _.text for _ in sent.spans}\n",
    "                words2 = {f'{_.id}': (_.text,  _.start) for _ in sent.tokens}\n",
    "                deps2 = {f'{_.start}': f'{_.head_id}' for _ in sent.tokens}\n",
    "                deps2_reverse = {v:k for k,v in deps2.items()}\n",
    "                for sp in spans2:\n",
    "                    s= f'{spans2[sp]}'\n",
    "                    deps2[sp]\n",
    "                    t, st = words2[deps2[sp]]\n",
    "                    s += f' {t}'\n",
    "                    \n",
    "                    print (s)                 \n",
    "                \n",
    "                #print (spans2)\n",
    "                #print (words2)\n",
    "                #print (deps2)\n",
    "                #print ('---------------')\n",
    "\n",
    "                #show_box_markup(sent.text, sent.spans)\n",
    "            '''\n",
    "            COUNTER -= 1\n",
    "\n",
    "\n",
    "CORPUS_PATH = 'C:\\\\tmp\\\\docs\\\\#learning\\\\article\\\\Python\\\\example\\\\corpus\\\\rbc'\n",
    "main(CORPUS_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "011cd8c709399e5a3560e5bf5cd6a761cb1d875b338266a72a63c2da03943d43"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
